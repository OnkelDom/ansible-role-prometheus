---
proxy_env: {}
prometheus_firewalld_state: "disabled"
prometheus_version: 2.20.0
prometheus_config_dir: /etc/prometheus
prometheus_config_file: config.yml
prometheus_db_dir: /var/lib/prometheus
prometheus_binary_install_dir: "/usr/local/bin"
prometheus_web_listen_address: "0.0.0.0"
prometheus_web_listen_port: 9090
prometheus_web_external_url: "http://localhost:{{ prometheus_web_listen_port }}"
prometheus_system_user: "{{ prometheus_user | default('prometheus') }}"
prometheus_system_group: "{{ prometheus_group | default('prometheus') }}"
prometheus_log_level: warn
prometheus_log_format: json
prometheus_create_consul_agent_service: true
prometheus_storage_retention_time: "7d"

prometheus_config_flags_extra: {}

#prometheus_alertmanager_config: []
prometheus_alertmanager_config: {}
#  - scheme: http
#     path_prefix: /alertmanager
#     basic_auth:
#       username: user
#       password: pass
#    static_configs:
#    - targets: ["127.0.0.1:9093"]
#     proxy_url: "127.0.0.2"

prometheus_alert_relabel_configs: []
# prometheus_alert_relabel_configs:
#  - action: labeldrop
#    regex: replica

prometheus_global: {}
#  scrape_interval: 15s
#  scrape_timeout: 10s
#  evaluation_interval: 15s

prometheus_remote_write: []
# prometheus_remote_write:
#   - url: https://dev.kausal.co/prom/push
#     basic_auth:
#       password: FOO

prometheus_remote_read: []
# prometheus_remote_read:
#   - url: https://demo.cloudalchemy.org:9201/read
#     basic_auth:
#       password: FOO

prometheus_external_labels:
  environment: "{{ ansible_fqdn | default(ansible_host) | default(inventory_hostname) }}"

prometheus_alert_rules_files:
  - prometheus/rules/*.rules

prometheus_static_targets_files:
  - prometheus/targets/*.yml
  - prometheus/targets/*.json

prometheus_targets: {}
#  node:
#    - targets:
#        - localhost:9100
#      labels:
#        env: test

prometheus_scrape_configs: {}
#  - job_name: "prometheus"
#    metrics_path: "{{ prometheus_metrics_path }}"
#    static_configs:
#      - targets:
#          - "{{ ansible_fqdn | default(ansible_host) | default('localhost') }}:{{ prometheus_web_listen_port }}"
#  - job_name: "node"
#    file_sd_configs:
#      - files:
#          - "{{ prometheus_config_dir }}/file_sd/*.json"

prometheus_alert_rules:
  - name: node_exporter
    rules:
    - alert: OutOfMemory
      expr: "node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Out of memory (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: UnusualNetworkThroughputIn
      expr: "sum by (instance) (irate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Unusual network throughput in (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: UnusualNetworkThroughputOut
      expr: "sum by (instance) (irate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Unusual network throughput out (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: UnusualDiskReadRate
      expr: "sum by (instance) (irate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Unusual disk read rate (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: UnusualDiskWriteRate
      expr: "sum by (instance) (irate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Unusual disk write rate (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: OutOfDiskSpace
      expr: 'node_filesystem_free_bytes{mountpoint ="/rootfs"} / node_filesystem_size_bytes{mountpoint ="/rootfs"} * 100 < 10'
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Out of disk space (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Disk is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: OutOfInodes
      expr: 'node_filesystem_files_free{mountpoint ="/rootfs"} / node_filesystem_files{mountpoint ="/rootfs"} * 100 < 10'
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Out of inodes (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: UnusualDiskReadLatency
      expr: "rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 100"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Unusual disk read latency (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: UnusualDiskWriteLatency
      expr: "rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 100"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Unusual disk write latency (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: HighCpuLoad
      expr: '100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80'
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}High CPU load (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: SwapIsFillingUp
      expr: "(1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) * 100 > 80"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Swap is filling up (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Swap is filling up (>80%)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: SystemdServiceCrashed
      expr: 'node_systemd_unit_state{state="failed"} == 1'
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}SystemD service crashed (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}SystemD service crashed\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: ProbeFailed
      expr: "probe_success == 0"
      for: 5m
      labels:
        severity: error
      annotations:
        summary: "{% raw %}Probe failed (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Probe failed\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: StatusCode
      expr: "probe_http_status_code <= 199 OR probe_http_status_code >= 400"
      for: 5m
      labels:
        severity: error
      annotations:
        summary: "{% raw %}Status Code (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}HTTP status code is not 200-399\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: SslCertificateWillExpireSoon
      expr: "probe_ssl_earliest_cert_expiry - time() < 86400 * 30"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}SSL certificate will expire soon (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}SSL certificate expires in 10 days\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: SslCertificateHasExpired
      expr: "probe_ssl_earliest_cert_expiry - time()  <= 0"
      for: 5m
      labels:
        severity: error
      annotations:
        summary: "{% raw %}SSL certificate has expired (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}SSL certificate has expired already\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: BlackboxSlowRequests
      expr: "probe_http_duration_seconds > 2"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Blackbox slow requests (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Blackbox request took more than 2s\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: BlackboxSlowPing
      expr: "probe_icmp_duration_seconds > 2"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Blackbox slow ping (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Blackbox ping took more than 2s\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: ExporterDown
      expr: "up == 0"
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "{% raw %}Exporter down (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Prometheus exporter down\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: AlertmanagerConfigurationReload
      expr: "alertmanager_config_last_reload_successful != 1"
      for: 5m
      labels:
        severity: error
      annotations:
        summary: "{% raw %}AlertManager configuration reload (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}AlertManager configuration reload error\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: PrometheusConfigurationReload
      expr: "prometheus_config_last_reload_successful != 1"
      for: 5m
      labels:
        severity: error
      annotations:
        summary: "{% raw %}Prometheus configuration reload (instance {{ $labels.instance }}){% endraw %}"
        description: "{% raw %}Prometheus configuration reload error\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
    - alert: InstanceDown
      expr: "up == 0"
      for: 5m
      labels:
        severity: critical
      annotations:
        description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}"
        summary: "{% raw %}Instance {{ $labels.instance }} down{% endraw %}"
    - alert: CriticalCPULoad
      expr: '100 - (avg by (instance) (irate(node_cpu_seconds_total{job="node",mode="idle"}[5m])) * 100) > 96'
      for: 2m
      labels:
        severity: critical
      annotations:
        description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has Critical CPU load for more than 2 minutes.{% endraw %}"
        summary: "{% raw %}Instance {{ $labels.instance }} - Critical CPU load{% endraw %}"
    - alert: CriticalRAMUsage
      expr: '(1 - ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes)) * 100 > 98'
      for: 5m
      labels:
        severity: critical
      annotations:
        description: "{% raw %}{{ $labels.instance }} has Critical Memory Usage more than 5 minutes.{% endraw %}"
        summary: "{% raw %}Instance {{ $labels.instance }} has Critical Memory Usage{% endraw %}"
    - alert: CriticalDiskSpace
      expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job="node"} / node_filesystem_size_bytes{job="node"} < 0.1'
      for: 4m
      labels:
        severity: critical
      annotations:
        description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 10% space remaining.{% endraw %}"
        summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"
    - alert: RebootRequired
      expr: "node_reboot_required > 0"
      labels:
        severity: warning
      annotations:
        description: "{% raw %}{{ $labels.instance }} requires a reboot.{% endraw %}"
        summary: "{% raw %}Instance {{ $labels.instance }} - reboot required{% endraw %}"
    - alert: ClockSkewDetected
      expr: 'abs(node_timex_offset_seconds) * 1000 > 30'
      for: 2m
      labels:
        severity: warning
      annotations:
        description: "{% raw %}Clock skew detected on {{ $labels.instance }}. Ensure NTP is configured correctly on this host.{% endraw %}"
        summary: "{% raw %}Instance {{ $labels.instance }} - Clock skew detected{% endraw %}"
